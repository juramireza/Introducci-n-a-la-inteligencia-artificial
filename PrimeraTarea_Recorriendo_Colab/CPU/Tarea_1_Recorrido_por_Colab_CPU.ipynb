{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tarea_1_Recorrido_por_Colab_CPU.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ti1Mfayq4_5P2XM7GaCWiKky14m6DwX9","authorship_tag":"ABX9TyMdrxl4lsz6th2sChDp6WOc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","## Lectura del set de datos\n","Así que crearemos inicialmente una función que nos permita cargar el set de imágenes de entrenamiento y validación, junto con la categoría a la que pertenece cada una de estas imágenes:\n"],"metadata":{"id":"nEQNKZDd3zIh"}},{"cell_type":"code","source":["#En esta celda crearemos inicialmente una función que nos permita cargar el set de imágenes de entrenamiento y validación, junto con la categoría a la que pertenece cada una de estas imágenes:\n","import numpy as np\n","import os\n","import gzip\n","\n","def load_set(ruta, tipo='train'):\n","\n","  ruta_categorias = os.path.join(ruta, '%s-labels-idx1-ubyte.gz' % tipo)\n","  ruta_imagenes = os.path.join(ruta, '%s-images-idx3-ubyte.gz' % tipo)\n","    \n","  with gzip.open(ruta_categorias, 'rb') as rut_cat:\n","      etiquetas = np.frombuffer(rut_cat.read(), dtype=np.uint8, offset=8)\n","\n","  with gzip.open(ruta_imagenes, 'rb') as rut_imgs:\n","      imagenes = np.frombuffer(rut_imgs.read(), dtype=np.uint8, offset=16).reshape(len(etiquetas), 784)\n","\n","  return imagenes, etiquetas\n"],"metadata":{"id":"MKTspR8f7E8j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Acceso a google drive\n","Ahora sí vamos a importar la librería “drive” de Google Colab, que nos permitirá hacer la lectura de datos desde Google Drive. Una vez importada la librería, “montamos” nuestro “drive” en el servidor remoto de Google Colab y luego definimos la ruta completa en donde se encuentran almacenados los datos.\n","\n","Estas son entonces las líneas de código que permiten acceder al “drive” y cargar el set de datos generando los respectivos sets de entrenamiento y validación:"],"metadata":{"id":"12Kc81rSQvT0"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","ruta = '/content/drive/MyDrive/Fashion_MNIST'\n","\n","X_train, Y_train = load_set(ruta, tipo='train')\n","X_test, Y_test = load_set(ruta, tipo='test')\n"],"metadata":{"id":"Rd7dDMi03vjE","executionInfo":{"status":"ok","timestamp":1647311926710,"user_tz":300,"elapsed":2248,"user":{"displayName":"Juan David Ramirez Avila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17968284916782554478"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7bdc24ca-d9e8-471d-e837-2f2a7d73c9a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Reajustar el tamaño de los datos\n","El set de datos debe contener una cantidad de datos que sea múltiplo de 128. Ya que para entrenar con la arquitectura de TPU, se necesita que el número de datos sea múltilo de 128, es decir, 128,256,512 y así sucesivamente. Es bueno mencionar, que esto no es necesario para entrenar con CPU o con GPU, pero la idea de este ejercicio es comparar los tiempos de entrenamiento, entonces, con este fin normalizaremos los valores de entrada al modelo en este paso. \n","\n","- El conjunto de datos de entrenamiento tiene 60000 datos, número más cercano a este, que es múltiplo de 128, es 59904.\n","-El conjunto de datos de entrenamiento tiene 10000 datos, número más cercano a este, que es múltiplo de 128, es 9984. \n","\n","**¿Preguntar como hacer el cálculo de los múltiplos?**\n","\n","**Preguntar este parrafo: Finalmente, usamos “reshape” para reajustar el tamaño de los sets de entrenamiento y validación y así garantizar que cada dato es una imagen en escala de grises de 28 x 28 pixeles, que será la entrada a la red convolucional que queremos entrenar**"],"metadata":{"id":"E7ULNP36O-st"}},{"cell_type":"code","source":["X_train = X_train[0:59904,:]\n","X_test = X_test[0:9984,:]\n","Y_train = Y_train[0:59904]\n","Y_test = Y_test[0:9984]\n","\n","X_train = np.reshape(X_train,(59904,28,28,1))\n","X_test = np.reshape(X_test,(9984,28,28,1))"],"metadata":{"id":"O1QzbS5h5lrL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Importar tensorflow 2 (ya incluye Keras)"],"metadata":{"id":"-Prmh_d4Q4Or"}},{"cell_type":"code","source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","print('Versión de Tensorflow: ' + tf.__version__)"],"metadata":{"id":"9ESugUv2Q8iz","executionInfo":{"status":"ok","timestamp":1647311932306,"user_tz":300,"elapsed":378,"user":{"displayName":"Juan David Ramirez Avila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17968284916782554478"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"83b76b83-2531-4dd4-b386-35ff74906040"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Versión de Tensorflow: 2.8.0\n"]}]},{"cell_type":"code","source":["##Definimos la semilla, para que el entrenamiento del modelo sea comparable, cuando se hace por CPU, GPU y TPU. \n","tf.random.set_seed(200)\n","\n","#Se crea el contenedor del modelo con el módulo secuencial \n","model = tf.keras.models.Sequential()\n","#Se definen las tres capas convolucionales\n","\n","#Primera capa convolucional (Filtros 64),, primero se hace una normalización sobre los datos, para facilitar el proceso de convergencia, posteriormente se agregan los filtros\n","#, a continuación se agrega la capa de max pooling, para reducir las dimensiones y por último se agrega una capa de dropout para evitar el sobre-ajuste. \n","#esto se repite para las tres capas convolucionales. \n","\n","model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","#Segunda capa convolucional (Filtros 128)\n","model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","#Tercera capa convolucional (Filtros 256)\n","model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n","model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n","model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","model.add(tf.keras.layers.Dropout(0.25))\n","\n","#Se aplanan los datos para convertirlos en vectores con el módulo Flatten. \n","model.add(tf.keras.layers.Flatten())\n","#Se agrega una red neuronal con 256 neuronas\n","model.add(tf.keras.layers.Dense(256))\n","model.add(tf.keras.layers.Activation('elu'))\n","model.add(tf.keras.layers.Dropout(0.5))\n","#Se declara la salida de la red neuronal con 10 neuronas y con la función de activación softmax, para realizar el proceso de clasificación de las imágenes. \n","model.add(tf.keras.layers.Dense(10))\n","model.add(tf.keras.layers.Activation('softmax'))\n","model.summary()\n","\n","#Se define el optimizador, la función de error y la métrica de desempeño. \n","model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"uQ_FZDMkRL7t","executionInfo":{"status":"ok","timestamp":1647311934805,"user_tz":300,"elapsed":786,"user":{"displayName":"Juan David Ramirez Avila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17968284916782554478"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8daaa7d-2139-4b52-b182-56319d3f71d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," batch_normalization_9 (Batc  (None, 28, 28, 1)        4         \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 28, 28, 64)        1664      \n","                                                                 \n"," max_pooling2d_9 (MaxPooling  (None, 14, 14, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_12 (Dropout)        (None, 14, 14, 64)        0         \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 14, 14, 64)       256       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 14, 14, 128)       204928    \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 7, 7, 128)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_13 (Dropout)        (None, 7, 7, 128)         0         \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 7, 7, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 7, 7, 256)         819456    \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 3, 3, 256)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_14 (Dropout)        (None, 3, 3, 256)         0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 2304)              0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               590080    \n","                                                                 \n"," activation_6 (Activation)   (None, 256)               0         \n","                                                                 \n"," dropout_15 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_7 (Dense)             (None, 10)                2570      \n","                                                                 \n"," activation_7 (Activation)   (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 1,619,470\n","Trainable params: 1,619,084\n","Non-trainable params: 386\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["#Generar checkpoint"],"metadata":{"id":"_98wXOrqaU6I"}},{"cell_type":"code","source":["#Generar la dirección donde se guardan los datos\n","checkpoint_path=\"/content/drive/MyDrive/Introduccion_Inteligencia_Artificial/TalleresyTareas/PrimeraTarea/CPU\"\n","checkpoint_dir=os.path.dirname(checkpoint_path)\n","\n","#Crear una llamada que salva los modelos\n","cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=False,verbose=1)"],"metadata":{"id":"8i9NcBEaaZgR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Entrenamiento con CPU"],"metadata":{"id":"9g8ETuE_RQoz"}},{"cell_type":"code","source":["import timeit\n","\n","def entrenamiento_cpu():\n","  with tf.device('/cpu:0'):\n","    model.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1,callbacks=[cp_callback])\n","  \n","  return None\n","\n","cpu_time = timeit.timeit('entrenamiento_cpu()', number=1, setup='from __main__ import entrenamiento_cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uww6_EnaROL0","executionInfo":{"status":"ok","timestamp":1647314478452,"user_tz":300,"elapsed":1098688,"user":{"displayName":"Juan David Ramirez Avila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17968284916782554478"}},"outputId":"d8d33dd9-0562-468b-9735-863118858caa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","468/468 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9799\n","Epoch 1: saving model to /content/drive/MyDrive/Introduccion_Inteligencia_Artificial/TalleresyTareas/PrimeraTarea/CPU\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Introduccion_Inteligencia_Artificial/TalleresyTareas/PrimeraTarea/CPU/assets\n","468/468 [==============================] - 549s 1s/step - loss: 0.0750 - accuracy: 0.9799 - val_loss: 0.0600 - val_accuracy: 0.9838\n","Epoch 2/2\n","468/468 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9823\n","Epoch 2: saving model to /content/drive/MyDrive/Introduccion_Inteligencia_Artificial/TalleresyTareas/PrimeraTarea/CPU\n","INFO:tensorflow:Assets written to: /content/drive/MyDrive/Introduccion_Inteligencia_Artificial/TalleresyTareas/PrimeraTarea/CPU/assets\n","468/468 [==============================] - 550s 1s/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 0.0327 - val_accuracy: 0.9919\n"]}]},{"cell_type":"code","source":["print('Tiempo de entrenamiento ' + str(cpu_time)+ ' segundos')"],"metadata":{"id":"hft2lqXfRkbX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647313347140,"user_tz":300,"elapsed":313,"user":{"displayName":"Juan David Ramirez Avila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17968284916782554478"}},"outputId":"ea85c8f2-d5ce-4730-97ea-8e3c14f7e317"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tiempo de entrenamiento 1131.0402922320009 segundos\n"]}]}]}